{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e24b58c",
   "metadata": {},
   "source": [
    "# YZM304 Ödev 2: CNN Özellik Çıkarımı ve Sınıflandırma  \n",
    "**Ders:** YZM304 Derin Öğrenme  \n",
    "**Dönem:** Bahar 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d29438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan cihaz: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# GPU varsa kullan, yoksa CPU ile çalış\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Kullanılan cihaz:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0a8a6",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Önişleme  \n",
    "MNIST veri setini normalize ederek yükle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8aa4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf490e",
   "metadata": {},
   "source": [
    "## Model Tanımları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b537c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Model 2: BatchNorm ve Dropout eklenmiş LeNet-5\n",
    "class LeNet5_BN_Drop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1    = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1      = nn.BatchNorm2d(6)\n",
    "        self.pool     = nn.MaxPool2d(2, 2)\n",
    "        self.conv2    = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2      = nn.BatchNorm2d(16)\n",
    "        self.fc1      = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2      = nn.Linear(120, 84)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3      = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout2(torch.relu(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Model 3: MNIST için uyarlanmış ön-eğitimli AlexNet\n",
    "class PretrainedAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.alexnet(pretrained=False)\n",
    "        self.model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Model 5: Özel Derin CNN\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1   = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2   = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3   = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool    = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1     = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2     = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f9a46",
   "metadata": {},
   "source": [
    "## Eğitim ve Değerlendirme Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4629f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    preds, true = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            true.extend(labels.cpu().numpy())\n",
    "    loss = running_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(true, preds)\n",
    "    cm  = confusion_matrix(true, preds)\n",
    "    return loss, acc, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8bdef",
   "metadata": {},
   "source": [
    "## Model 1 Eğitimi ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3003d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 Epoch 1/10 - Test Doğruluk: 0.9786\n",
      "Model1 Epoch 2/10 - Test Doğruluk: 0.9826\n",
      "Model1 Epoch 3/10 - Test Doğruluk: 0.9830\n",
      "Model1 Epoch 4/10 - Test Doğruluk: 0.9809\n",
      "Model1 Epoch 5/10 - Test Doğruluk: 0.9821\n",
      "Model1 Epoch 6/10 - Test Doğruluk: 0.9843\n",
      "Model1 Epoch 7/10 - Test Doğruluk: 0.9790\n",
      "Model1 Epoch 8/10 - Test Doğruluk: 0.9801\n",
      "Model1 Epoch 9/10 - Test Doğruluk: 0.9842\n",
      "Model1 Epoch 10/10 - Test Doğruluk: 0.9803\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "results = {}\n",
    "model1 = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model1, train_loader, criterion, optimizer1, device)\n",
    "    val_loss, val_acc, _ = evaluate(model1, test_loader, criterion, device)\n",
    "    print(f\"Model1 Epoch {epoch+1}/{num_epochs} - Test Doğruluk: {val_acc:.4f}\")\n",
    "results['Model1'] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449c674",
   "metadata": {},
   "source": [
    "## Model 2 Eğitimi ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157e5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2 Epoch 1/10 - Test Doğruluk: 0.9091\n",
      "Model2 Epoch 2/10 - Test Doğruluk: 0.9440\n",
      "Model2 Epoch 3/10 - Test Doğruluk: 0.9500\n",
      "Model2 Epoch 4/10 - Test Doğruluk: 0.9474\n",
      "Model2 Epoch 5/10 - Test Doğruluk: 0.9309\n",
      "Model2 Epoch 6/10 - Test Doğruluk: 0.9515\n",
      "Model2 Epoch 7/10 - Test Doğruluk: 0.9518\n",
      "Model2 Epoch 8/10 - Test Doğruluk: 0.9593\n",
      "Model2 Epoch 9/10 - Test Doğruluk: 0.9646\n",
      "Model2 Epoch 10/10 - Test Doğruluk: 0.9712\n"
     ]
    }
   ],
   "source": [
    "model2 = LeNet5_BN_Drop().to(device)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model2, train_loader, criterion, optimizer2, device)\n",
    "    val_loss, val_acc, _ = evaluate(model2, test_loader, criterion, device)\n",
    "    print(f\"Model2 Epoch {epoch+1}/{num_epochs} - Test Doğruluk: {val_acc:.4f}\")\n",
    "results['Model2'] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf463cb",
   "metadata": {},
   "source": [
    "## Model 3 Eğitimi ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff68c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ERIS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ERIS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3 Epoch 1/10 - Test Doğruluk: 0.9787\n",
      "Model3 Epoch 2/10 - Test Doğruluk: 0.9817\n",
      "Model3 Epoch 3/10 - Test Doğruluk: 0.9895\n",
      "Model3 Epoch 4/10 - Test Doğruluk: 0.9869\n",
      "Model3 Epoch 5/10 - Test Doğruluk: 0.9888\n",
      "Model3 Epoch 6/10 - Test Doğruluk: 0.9878\n",
      "Model3 Epoch 7/10 - Test Doğruluk: 0.9910\n",
      "Model3 Epoch 8/10 - Test Doğruluk: 0.9907\n",
      "Model3 Epoch 9/10 - Test Doğruluk: 0.9907\n",
      "Model3 Epoch 10/10 - Test Doğruluk: 0.9904\n"
     ]
    }
   ],
   "source": [
    "model3 = PretrainedAlexNet().to(device)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model3, train_loader, criterion, optimizer3, device)\n",
    "    val_loss, val_acc, _ = evaluate(model3, test_loader, criterion, device)\n",
    "    print(f\"Model3 Epoch {epoch+1}/{num_epochs} - Test Doğruluk: {val_acc:.4f}\")\n",
    "results['Model3'] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3ed53",
   "metadata": {},
   "source": [
    "Burada aldığım hata kodu etkilemediği ve üstteki sütun yaklaşık 15 dakikada çalıştığı için düzeltip yeniden çalıştırma gereği duymadım."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d50760",
   "metadata": {},
   "source": [
    "## Model 4: Hibrit CNN + SVM Özellik Çıkarımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6b0f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hibrit Model (SVM) Test Doğruluk: 0.9776\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = nn.Sequential(\n",
    "    model2.conv1, model2.bn1, nn.ReLU(), model2.pool,\n",
    "    model2.conv2, model2.bn2, nn.ReLU(), model2.pool,\n",
    "    nn.Flatten(),\n",
    "    model2.fc1, nn.ReLU(),\n",
    "    model2.fc2, nn.ReLU()\n",
    ").to(device)\n",
    "feature_extractor.eval()\n",
    "train_feats, train_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, lbls in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        feats = feature_extractor(inputs)\n",
    "        train_feats.append(feats.cpu().numpy())\n",
    "        train_labels.append(lbls.numpy())\n",
    "train_feats = np.concatenate(train_feats)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "np.save('features.npy', train_feats)\n",
    "np.save('labels.npy', train_labels)\n",
    "svm = SVC()\n",
    "svm.fit(train_feats, train_labels)\n",
    "test_feats, test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, lbls in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        feats = feature_extractor(inputs)\n",
    "        test_feats.append(feats.cpu().numpy())\n",
    "        test_labels.append(lbls.numpy())\n",
    "test_feats  = np.concatenate(test_feats)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "svm_preds = svm.predict(test_feats)\n",
    "svm_acc = accuracy_score(test_labels, svm_preds)\n",
    "print(f\"Hibrit Model (SVM) Test Doğruluk: {svm_acc:.4f}\")\n",
    "results['Model4_SVM'] = svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b812e",
   "metadata": {},
   "source": [
    "## Model 5 Eğitimi ve Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be98047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model5 Epoch 1/10 - Test Doğruluk: 0.9802\n",
      "Model5 Epoch 2/10 - Test Doğruluk: 0.9834\n",
      "Model5 Epoch 3/10 - Test Doğruluk: 0.9856\n",
      "Model5 Epoch 4/10 - Test Doğruluk: 0.9871\n",
      "Model5 Epoch 5/10 - Test Doğruluk: 0.9845\n",
      "Model5 Epoch 6/10 - Test Doğruluk: 0.9869\n",
      "Model5 Epoch 7/10 - Test Doğruluk: 0.9868\n",
      "Model5 Epoch 8/10 - Test Doğruluk: 0.9875\n",
      "Model5 Epoch 9/10 - Test Doğruluk: 0.9876\n",
      "Model5 Epoch 10/10 - Test Doğruluk: 0.9873\n"
     ]
    }
   ],
   "source": [
    "model5 = CustomCNN().to(device)\n",
    "optimizer5 = optim.Adam(model5.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model5, train_loader, criterion, optimizer5, device)\n",
    "    val_loss, val_acc, _ = evaluate(model5, test_loader, criterion, device)\n",
    "    print(f\"Model5 Epoch {epoch+1}/{num_epochs} - Test Doğruluk: {val_acc:.4f}\")\n",
    "results['Model5'] = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89346b3e",
   "metadata": {},
   "source": [
    "## Sonuçların Özeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe150d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1: Test Doğruluk = 0.9803\n",
      "Model2: Test Doğruluk = 0.9712\n",
      "Model3: Test Doğruluk = 0.9904\n",
      "Model4_SVM: Test Doğruluk = 0.9776\n",
      "Model5: Test Doğruluk = 0.9873\n"
     ]
    }
   ],
   "source": [
    "for name, acc in results.items():\n",
    "    print(f\"{name}: Test Doğruluk = {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
